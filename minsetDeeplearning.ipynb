{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "minset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rajanikant/ML/blob/master/minsetDeeplearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdFYtja8qpKl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import h5py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SUEAD_TsT8c",
        "colab_type": "code",
        "outputId": "9ddcbc40-e11d-4c50-8d8d-f37603fb7bc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "#import io\n",
        "#f = h5py.File('https://drive.google.com/open?id=1MPpbNT3gSanUJwd3KPdszz_pfcWSLopR', 'r')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6ejl02Fr8Ic",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root_path = 'gdrive/My Drive/ColabNotebooks/SVHN_single_grey1.h5'\n",
        "f = h5py.File(root_path, 'r')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0rzLrS5MEnk",
        "colab_type": "code",
        "outputId": "e817bea2-b043-4eca-98e5-55398b999326",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "list(f.keys())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['X_test', 'X_train', 'X_val', 'y_test', 'y_train', 'y_val']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_M8HGPwMP1F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ouepnGKMWiF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = np.array(f['X_train']).reshape((f['X_train'].shape[0], -1))\n",
        "X_test = np.array(f['X_test']).reshape((f['X_test'].shape[0], -1))\n",
        "y_train = np.array(f['y_train']).reshape((f['y_train'].shape[0], -1))\n",
        "y_test = np.array(f['y_test']).reshape((f['y_test'].shape[0], -1))\n",
        "X_val = np.array(f['X_val']).reshape((f['X_val'].shape[0], -1))\n",
        "y_val = np.array(f['y_val']).reshape((f['y_val'].shape[0], -1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lu1e9Zkftixh",
        "colab_type": "code",
        "outputId": "d53b139d-6b1f-494e-da82-ac1fb2871425",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# # normalize inputs from 0-255 to 0-1\n",
        "train_features = X_train / 255.0\n",
        "test_features = X_test / 255.0\n",
        "val_feature = X_val/255.0\n",
        "\n",
        "print(y_train.shape)\n",
        "print (y_test.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(42000, 1)\n",
            "(18000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJF9BUxfMa9i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = pd.DataFrame(X_train)\n",
        "X_test = pd.DataFrame(X_test)\n",
        "y_train = pd.DataFrame(y_train)\n",
        "y_test = pd.DataFrame(y_test)\n",
        "X_val = pd.DataFrame(X_val)\n",
        "y_val = pd.DataFrame(y_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ix96M8a2MgE8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import warnings; \n",
        "warnings.simplefilter('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIgEP01zdENX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "c1306338-477e-4745-f773-51a9dee69c68"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dense\n",
        "from keras import optimizers\n",
        "from keras.utils.np_utils import to_categorical\n",
        "# converting y data into categorical (one-hot encoding)\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "model = Sequential()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMA6ES5IdXxF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "3345d79f-9742-4dc3-fccf-90e5125a72c4"
      },
      "source": [
        "model.add(Dense(1024, input_shape = (1024, )))\n",
        "model.add(Activation('sigmoid'))\n",
        "model.add(Dense(1024))\n",
        "model.add(Activation('sigmoid'))\n",
        "model.add(Dense(1024))\n",
        "model.add(Activation('sigmoid'))\n",
        "model.add(Dense(1024))\n",
        "model.add(Activation('sigmoid'))\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmHOgTg-dfNY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "9289e37b-5692-4cd8-9faf-4c2c5a50d41d"
      },
      "source": [
        "sgd = optimizers.SGD(lr = 0.01)\n",
        "model.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxtExVaLdjRk",
        "colab_type": "code",
        "outputId": "4eb12f5f-acb8-4d62-f50a-d22dbf259e30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(X_train, y_train, batch_size = 200, epochs = 100, verbose = 1)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "42000/42000 [==============================] - 19s 461us/step - loss: 2.3096 - acc: 0.1015\n",
            "Epoch 2/100\n",
            "42000/42000 [==============================] - 19s 455us/step - loss: 2.3061 - acc: 0.1034\n",
            "Epoch 3/100\n",
            "42000/42000 [==============================] - 19s 453us/step - loss: 2.3059 - acc: 0.0982\n",
            "Epoch 4/100\n",
            "42000/42000 [==============================] - 19s 461us/step - loss: 2.3052 - acc: 0.1034\n",
            "Epoch 5/100\n",
            "42000/42000 [==============================] - 19s 453us/step - loss: 2.3057 - acc: 0.1016\n",
            "Epoch 6/100\n",
            "42000/42000 [==============================] - 19s 453us/step - loss: 2.3051 - acc: 0.0989\n",
            "Epoch 7/100\n",
            "42000/42000 [==============================] - 19s 454us/step - loss: 2.3050 - acc: 0.1057\n",
            "Epoch 8/100\n",
            "42000/42000 [==============================] - 19s 452us/step - loss: 2.3047 - acc: 0.1056\n",
            "Epoch 9/100\n",
            "42000/42000 [==============================] - 19s 453us/step - loss: 2.3047 - acc: 0.1038\n",
            "Epoch 10/100\n",
            "42000/42000 [==============================] - 19s 454us/step - loss: 2.3046 - acc: 0.1033\n",
            "Epoch 11/100\n",
            "42000/42000 [==============================] - 19s 455us/step - loss: 2.3043 - acc: 0.1036\n",
            "Epoch 12/100\n",
            "42000/42000 [==============================] - 19s 462us/step - loss: 2.3044 - acc: 0.1048\n",
            "Epoch 13/100\n",
            "42000/42000 [==============================] - 19s 455us/step - loss: 2.3041 - acc: 0.1050\n",
            "Epoch 14/100\n",
            "42000/42000 [==============================] - 19s 453us/step - loss: 2.3040 - acc: 0.1038\n",
            "Epoch 15/100\n",
            "42000/42000 [==============================] - 19s 452us/step - loss: 2.3034 - acc: 0.1039\n",
            "Epoch 16/100\n",
            "42000/42000 [==============================] - 19s 453us/step - loss: 2.3037 - acc: 0.1048\n",
            "Epoch 17/100\n",
            "42000/42000 [==============================] - 19s 463us/step - loss: 2.3038 - acc: 0.1040\n",
            "Epoch 18/100\n",
            "42000/42000 [==============================] - 19s 455us/step - loss: 2.3031 - acc: 0.1070\n",
            "Epoch 19/100\n",
            "42000/42000 [==============================] - 20s 466us/step - loss: 2.3034 - acc: 0.1057\n",
            "Epoch 20/100\n",
            "42000/42000 [==============================] - 19s 454us/step - loss: 2.3026 - acc: 0.1089\n",
            "Epoch 21/100\n",
            "42000/42000 [==============================] - 19s 458us/step - loss: 2.3026 - acc: 0.1091\n",
            "Epoch 22/100\n",
            "42000/42000 [==============================] - 19s 451us/step - loss: 2.3025 - acc: 0.1066\n",
            "Epoch 23/100\n",
            "42000/42000 [==============================] - 19s 454us/step - loss: 2.3024 - acc: 0.1070\n",
            "Epoch 24/100\n",
            "42000/42000 [==============================] - 19s 453us/step - loss: 2.3018 - acc: 0.1103\n",
            "Epoch 25/100\n",
            "42000/42000 [==============================] - 19s 459us/step - loss: 2.3021 - acc: 0.1067\n",
            "Epoch 26/100\n",
            "42000/42000 [==============================] - 19s 454us/step - loss: 2.3019 - acc: 0.1080\n",
            "Epoch 27/100\n",
            "42000/42000 [==============================] - 19s 453us/step - loss: 2.3014 - acc: 0.1089\n",
            "Epoch 28/100\n",
            "42000/42000 [==============================] - 19s 461us/step - loss: 2.3014 - acc: 0.1098\n",
            "Epoch 29/100\n",
            "42000/42000 [==============================] - 19s 455us/step - loss: 2.3013 - acc: 0.1108\n",
            "Epoch 30/100\n",
            "42000/42000 [==============================] - 19s 454us/step - loss: 2.3007 - acc: 0.1106\n",
            "Epoch 31/100\n",
            "42000/42000 [==============================] - 19s 458us/step - loss: 2.3000 - acc: 0.1103\n",
            "Epoch 32/100\n",
            "42000/42000 [==============================] - 19s 461us/step - loss: 2.3000 - acc: 0.1104\n",
            "Epoch 33/100\n",
            "42000/42000 [==============================] - 19s 462us/step - loss: 2.2999 - acc: 0.1124\n",
            "Epoch 34/100\n",
            "42000/42000 [==============================] - 19s 458us/step - loss: 2.2997 - acc: 0.1104\n",
            "Epoch 35/100\n",
            "42000/42000 [==============================] - 19s 459us/step - loss: 2.2992 - acc: 0.1150\n",
            "Epoch 36/100\n",
            "42000/42000 [==============================] - 19s 458us/step - loss: 2.2982 - acc: 0.1145\n",
            "Epoch 37/100\n",
            "42000/42000 [==============================] - 19s 463us/step - loss: 2.2985 - acc: 0.1156\n",
            "Epoch 38/100\n",
            "42000/42000 [==============================] - 19s 463us/step - loss: 2.2982 - acc: 0.1109\n",
            "Epoch 39/100\n",
            "42000/42000 [==============================] - 19s 458us/step - loss: 2.2976 - acc: 0.1135\n",
            "Epoch 40/100\n",
            "42000/42000 [==============================] - 19s 456us/step - loss: 2.2977 - acc: 0.1162\n",
            "Epoch 41/100\n",
            "42000/42000 [==============================] - 19s 456us/step - loss: 2.2967 - acc: 0.1186\n",
            "Epoch 42/100\n",
            "42000/42000 [==============================] - 19s 460us/step - loss: 2.2962 - acc: 0.1166\n",
            "Epoch 43/100\n",
            "42000/42000 [==============================] - 19s 456us/step - loss: 2.2957 - acc: 0.1252\n",
            "Epoch 44/100\n",
            "42000/42000 [==============================] - 20s 466us/step - loss: 2.2950 - acc: 0.1244\n",
            "Epoch 45/100\n",
            "42000/42000 [==============================] - 19s 460us/step - loss: 2.2951 - acc: 0.1213\n",
            "Epoch 46/100\n",
            "42000/42000 [==============================] - 19s 458us/step - loss: 2.2945 - acc: 0.1277\n",
            "Epoch 47/100\n",
            "42000/42000 [==============================] - 19s 454us/step - loss: 2.2929 - acc: 0.1308\n",
            "Epoch 48/100\n",
            "42000/42000 [==============================] - 19s 457us/step - loss: 2.2927 - acc: 0.1258\n",
            "Epoch 49/100\n",
            "42000/42000 [==============================] - 19s 456us/step - loss: 2.2917 - acc: 0.1271\n",
            "Epoch 50/100\n",
            "42000/42000 [==============================] - 20s 465us/step - loss: 2.2909 - acc: 0.1334\n",
            "Epoch 51/100\n",
            "42000/42000 [==============================] - 19s 461us/step - loss: 2.2900 - acc: 0.1340\n",
            "Epoch 52/100\n",
            "42000/42000 [==============================] - 19s 460us/step - loss: 2.2889 - acc: 0.1359\n",
            "Epoch 53/100\n",
            "42000/42000 [==============================] - 19s 461us/step - loss: 2.2880 - acc: 0.1431\n",
            "Epoch 54/100\n",
            "42000/42000 [==============================] - 19s 463us/step - loss: 2.2865 - acc: 0.1420\n",
            "Epoch 55/100\n",
            "42000/42000 [==============================] - 19s 462us/step - loss: 2.2857 - acc: 0.1436\n",
            "Epoch 56/100\n",
            "42000/42000 [==============================] - 19s 463us/step - loss: 2.2846 - acc: 0.1467\n",
            "Epoch 57/100\n",
            "42000/42000 [==============================] - 20s 465us/step - loss: 2.2830 - acc: 0.1480\n",
            "Epoch 58/100\n",
            "42000/42000 [==============================] - 19s 464us/step - loss: 2.2810 - acc: 0.1660\n",
            "Epoch 59/100\n",
            "42000/42000 [==============================] - 20s 471us/step - loss: 2.2793 - acc: 0.1519\n",
            "Epoch 60/100\n",
            "42000/42000 [==============================] - 20s 477us/step - loss: 2.2773 - acc: 0.1590\n",
            "Epoch 61/100\n",
            "42000/42000 [==============================] - 20s 469us/step - loss: 2.2743 - acc: 0.1672\n",
            "Epoch 62/100\n",
            "42000/42000 [==============================] - 20s 467us/step - loss: 2.2718 - acc: 0.1750\n",
            "Epoch 63/100\n",
            "42000/42000 [==============================] - 20s 472us/step - loss: 2.2689 - acc: 0.1767\n",
            "Epoch 64/100\n",
            "42000/42000 [==============================] - 20s 468us/step - loss: 2.2657 - acc: 0.1828\n",
            "Epoch 65/100\n",
            "42000/42000 [==============================] - 20s 467us/step - loss: 2.2612 - acc: 0.1940\n",
            "Epoch 66/100\n",
            "42000/42000 [==============================] - 20s 472us/step - loss: 2.2570 - acc: 0.2036\n",
            "Epoch 67/100\n",
            "42000/42000 [==============================] - 20s 473us/step - loss: 2.2506 - acc: 0.2033\n",
            "Epoch 68/100\n",
            "42000/42000 [==============================] - 20s 467us/step - loss: 2.2442 - acc: 0.2118\n",
            "Epoch 69/100\n",
            "42000/42000 [==============================] - 20s 470us/step - loss: 2.2372 - acc: 0.2193\n",
            "Epoch 70/100\n",
            "42000/42000 [==============================] - 20s 472us/step - loss: 2.2280 - acc: 0.2262\n",
            "Epoch 71/100\n",
            "42000/42000 [==============================] - 20s 474us/step - loss: 2.2171 - acc: 0.2323\n",
            "Epoch 72/100\n",
            "42000/42000 [==============================] - 20s 471us/step - loss: 2.2047 - acc: 0.2393\n",
            "Epoch 73/100\n",
            "42000/42000 [==============================] - 20s 468us/step - loss: 2.1891 - acc: 0.2465\n",
            "Epoch 74/100\n",
            "42000/42000 [==============================] - 20s 469us/step - loss: 2.1702 - acc: 0.2479\n",
            "Epoch 75/100\n",
            "42000/42000 [==============================] - 20s 472us/step - loss: 2.1484 - acc: 0.2596\n",
            "Epoch 76/100\n",
            "42000/42000 [==============================] - 20s 474us/step - loss: 2.1230 - acc: 0.2632\n",
            "Epoch 77/100\n",
            "42000/42000 [==============================] - 20s 465us/step - loss: 2.0942 - acc: 0.2644\n",
            "Epoch 78/100\n",
            "42000/42000 [==============================] - 20s 466us/step - loss: 2.0636 - acc: 0.2699\n",
            "Epoch 79/100\n",
            "42000/42000 [==============================] - 20s 472us/step - loss: 2.0327 - acc: 0.2777\n",
            "Epoch 80/100\n",
            "42000/42000 [==============================] - 20s 467us/step - loss: 2.0028 - acc: 0.2861\n",
            "Epoch 81/100\n",
            "42000/42000 [==============================] - 20s 465us/step - loss: 1.9742 - acc: 0.2932\n",
            "Epoch 82/100\n",
            "42000/42000 [==============================] - 20s 468us/step - loss: 1.9524 - acc: 0.2988\n",
            "Epoch 83/100\n",
            "42000/42000 [==============================] - 20s 470us/step - loss: 1.9302 - acc: 0.3049\n",
            "Epoch 84/100\n",
            "42000/42000 [==============================] - 20s 466us/step - loss: 1.9151 - acc: 0.3102\n",
            "Epoch 85/100\n",
            "42000/42000 [==============================] - 20s 466us/step - loss: 1.9001 - acc: 0.3194\n",
            "Epoch 86/100\n",
            "42000/42000 [==============================] - 20s 468us/step - loss: 1.8941 - acc: 0.3196\n",
            "Epoch 87/100\n",
            "42000/42000 [==============================] - 20s 474us/step - loss: 1.8880 - acc: 0.3214\n",
            "Epoch 88/100\n",
            "42000/42000 [==============================] - 19s 463us/step - loss: 1.8900 - acc: 0.3213\n",
            "Epoch 89/100\n",
            "42000/42000 [==============================] - 20s 465us/step - loss: 1.8841 - acc: 0.3240\n",
            "Epoch 90/100\n",
            "42000/42000 [==============================] - 20s 467us/step - loss: 1.8715 - acc: 0.3301\n",
            "Epoch 91/100\n",
            "42000/42000 [==============================] - 20s 469us/step - loss: 1.8675 - acc: 0.3285\n",
            "Epoch 92/100\n",
            "42000/42000 [==============================] - 20s 470us/step - loss: 1.8707 - acc: 0.3269\n",
            "Epoch 93/100\n",
            "42000/42000 [==============================] - 20s 485us/step - loss: 1.8624 - acc: 0.3260\n",
            "Epoch 94/100\n",
            "42000/42000 [==============================] - 20s 466us/step - loss: 1.8692 - acc: 0.3224\n",
            "Epoch 95/100\n",
            "42000/42000 [==============================] - 20s 469us/step - loss: 1.8636 - acc: 0.3261\n",
            "Epoch 96/100\n",
            "42000/42000 [==============================] - 20s 467us/step - loss: 1.8636 - acc: 0.3228\n",
            "Epoch 97/100\n",
            "42000/42000 [==============================] - 20s 465us/step - loss: 1.8598 - acc: 0.3193\n",
            "Epoch 98/100\n",
            "42000/42000 [==============================] - 20s 469us/step - loss: 1.8684 - acc: 0.3137\n",
            "Epoch 99/100\n",
            "42000/42000 [==============================] - 20s 471us/step - loss: 1.8565 - acc: 0.3175\n",
            "Epoch 100/100\n",
            "42000/42000 [==============================] - 20s 468us/step - loss: 1.8654 - acc: 0.3115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L95f2AJCiwYM",
        "colab_type": "code",
        "outputId": "174d39d0-48e8-4e4e-94dc-001a80d978e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "results = model.evaluate(X_test, y_test)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18000/18000 [==============================] - 5s 283us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_C6aI0i5jVMc",
        "colab_type": "code",
        "outputId": "63e0fef3-16db-4eda-fddc-f61b6c3cd5b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Test accuracy: ', results[1])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy:  0.3267777777777778\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bO7nwIpljbXR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(1024, input_shape = (1024, )))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pf2N3ErkASA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sgd = optimizers.SGD(lr = 0.01)\n",
        "model.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTlzK_2pkF1o",
        "colab_type": "code",
        "outputId": "c4a1918b-34ae-4ee5-fc1e-b52b431b11c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(X_train, y_train, batch_size = 200, epochs = 100, verbose = 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "42000/42000 [==============================] - 5s 120us/step - loss: 14.5065 - acc: 0.0995\n",
            "Epoch 2/100\n",
            "42000/42000 [==============================] - 5s 116us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 3/100\n",
            "42000/42000 [==============================] - 5s 117us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 4/100\n",
            "42000/42000 [==============================] - 5s 117us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 5/100\n",
            "42000/42000 [==============================] - 5s 114us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 6/100\n",
            "42000/42000 [==============================] - 5s 116us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 7/100\n",
            "42000/42000 [==============================] - 5s 118us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 8/100\n",
            "42000/42000 [==============================] - 5s 116us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 9/100\n",
            "42000/42000 [==============================] - 5s 114us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 10/100\n",
            "42000/42000 [==============================] - 5s 117us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 11/100\n",
            "42000/42000 [==============================] - 5s 114us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 12/100\n",
            "42000/42000 [==============================] - 5s 116us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 13/100\n",
            "42000/42000 [==============================] - 5s 114us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 14/100\n",
            "42000/42000 [==============================] - 5s 113us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 15/100\n",
            "42000/42000 [==============================] - 5s 114us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 16/100\n",
            "42000/42000 [==============================] - 5s 114us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 17/100\n",
            "42000/42000 [==============================] - 5s 116us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 18/100\n",
            "42000/42000 [==============================] - 5s 117us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 19/100\n",
            "42000/42000 [==============================] - 5s 119us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 20/100\n",
            "42000/42000 [==============================] - 5s 118us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 21/100\n",
            "42000/42000 [==============================] - 5s 115us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 22/100\n",
            "42000/42000 [==============================] - 5s 115us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 23/100\n",
            "42000/42000 [==============================] - 5s 119us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 24/100\n",
            "42000/42000 [==============================] - 5s 120us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 25/100\n",
            "42000/42000 [==============================] - 5s 115us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 26/100\n",
            "42000/42000 [==============================] - 5s 114us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 27/100\n",
            "42000/42000 [==============================] - 5s 114us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 28/100\n",
            "42000/42000 [==============================] - 5s 115us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 29/100\n",
            "42000/42000 [==============================] - 5s 116us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 30/100\n",
            "42000/42000 [==============================] - 5s 116us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 31/100\n",
            "42000/42000 [==============================] - 5s 114us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 32/100\n",
            "42000/42000 [==============================] - 5s 114us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 33/100\n",
            "42000/42000 [==============================] - 5s 113us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 34/100\n",
            "42000/42000 [==============================] - 5s 114us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 35/100\n",
            "42000/42000 [==============================] - 5s 114us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 36/100\n",
            "42000/42000 [==============================] - 5s 114us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 37/100\n",
            "42000/42000 [==============================] - 5s 115us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 38/100\n",
            "42000/42000 [==============================] - 5s 113us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 39/100\n",
            "42000/42000 [==============================] - 5s 113us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 40/100\n",
            "42000/42000 [==============================] - 5s 114us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 41/100\n",
            "42000/42000 [==============================] - 5s 117us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 42/100\n",
            "42000/42000 [==============================] - 5s 116us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 43/100\n",
            "42000/42000 [==============================] - 5s 116us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 44/100\n",
            "42000/42000 [==============================] - 5s 114us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 45/100\n",
            "42000/42000 [==============================] - 5s 114us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 46/100\n",
            "42000/42000 [==============================] - 5s 112us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 47/100\n",
            "42000/42000 [==============================] - 5s 113us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 48/100\n",
            "42000/42000 [==============================] - 5s 114us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 49/100\n",
            "42000/42000 [==============================] - 5s 118us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 50/100\n",
            "42000/42000 [==============================] - 5s 115us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 51/100\n",
            "42000/42000 [==============================] - 5s 115us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 52/100\n",
            "42000/42000 [==============================] - 5s 115us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 53/100\n",
            "42000/42000 [==============================] - 5s 115us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 54/100\n",
            "42000/42000 [==============================] - 5s 115us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 55/100\n",
            "42000/42000 [==============================] - 5s 116us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 56/100\n",
            "42000/42000 [==============================] - 5s 117us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 57/100\n",
            "42000/42000 [==============================] - 5s 115us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 58/100\n",
            "42000/42000 [==============================] - 5s 117us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 59/100\n",
            "42000/42000 [==============================] - 5s 116us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 60/100\n",
            "42000/42000 [==============================] - 5s 116us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 61/100\n",
            "42000/42000 [==============================] - 5s 116us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 62/100\n",
            "42000/42000 [==============================] - 5s 115us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 63/100\n",
            "42000/42000 [==============================] - 5s 112us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 64/100\n",
            "42000/42000 [==============================] - 5s 113us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 65/100\n",
            "42000/42000 [==============================] - 5s 115us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 66/100\n",
            "42000/42000 [==============================] - 5s 115us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 67/100\n",
            "42000/42000 [==============================] - 5s 116us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 68/100\n",
            "42000/42000 [==============================] - 5s 117us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 69/100\n",
            "42000/42000 [==============================] - 5s 113us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 70/100\n",
            "42000/42000 [==============================] - 5s 113us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 71/100\n",
            "42000/42000 [==============================] - 5s 113us/step - loss: 14.5109 - acc: 0.0997\n",
            "Epoch 72/100\n",
            "38200/42000 [==========================>...] - ETA: 0s - loss: 14.5160 - acc: 0.0994"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtlSWDDxkNfV",
        "colab_type": "code",
        "outputId": "817f55cb-36ea-4def-ffbf-3d8fcbad9183",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "results = model.evaluate(X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18000/18000 [==============================] - 0s 21us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fST9wYSkiab",
        "colab_type": "code",
        "outputId": "0d449f54-832b-4b1c-f32c-e8ae01ce39e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Test accuracy: ', results[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy:  0.10155555555555555\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdF8zK2Zkp6t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def mlp_model():\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Dense(50, input_shape = (1024, ), kernel_initializer='he_normal'))     # use he_normal initializer\n",
        "    model.add(Activation('sigmoid'))    \n",
        "    model.add(Dense(50, kernel_initializer='he_normal'))                            # use he_normal initializer\n",
        "    model.add(Activation('sigmoid'))    \n",
        "    model.add(Dense(50, kernel_initializer='he_normal'))                            # use he_normal initializer\n",
        "    model.add(Activation('sigmoid'))    \n",
        "    model.add(Dense(50, kernel_initializer='he_normal'))                            # use he_normal initializer\n",
        "    model.add(Activation('sigmoid'))    \n",
        "    model.add(Dense(10, kernel_initializer='he_normal'))                            # use he_normal initializer\n",
        "    model.add(Activation('softmax'))\n",
        "    \n",
        "    sgd = optimizers.SGD(lr = 0.001)\n",
        "    model.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}